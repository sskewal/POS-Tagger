{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Train file here\n",
    "\n",
    "filename = 'train.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\tThe/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd ``/`` no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\\n\\n\\n\\tThe/at jury/nn further/rbr said/vbd in/in term-end/nn presentments/nns that/cs the/at City/nn-tl Executive/jj-tl Committee/nn-tl ,/, which/wdt had/hvd over-all/jj charge/nn of/in the/at election/nn ,/, ``/`` deserves/vbz the/at praise/nn and/c\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The at Fulton np-tl County nn-tl Grand jj-tl Jury nn-tl said vbd Friday nr an at investigation nn of in Atlanta's np$ recent jj primary nn election nn produced vbd  no at evidence nn  that cs any dti irregularities nns took vbd place nnThe at jury nn further rbr said vbd in in term-end nn presentments nns that cs the at City nn-tl Executive jj-tl Committee nn-tlwhich wdt had hvd over-all jj charge nn of in the at election nn deserves vbz the at praise nn and cc thanks nns of in the at City nn-tl of in-tl Atlanta np-tl  for in the at manner nn in in which wdt the at election nn was bedz conducted vbnThe at September-October np term nn jury nn had hvd been ben charged vbn by in Fulton np-tl Superior jj-tl Court nn-tl Judge nn-tl Durwood np Pye np to to investigate vb reports nns of in possible jj  irregularities nns  in in the at hard-fought jj primary nn which wdt was bedz won vbn by in Mayor-nominate nn-tl Ivan np Allen np Jr. np Only rb a at relative jj handful nn of in such jj repor\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=re.sub(\"\\s+\",' ',text)\n",
    "text=re.sub(\"``/``\",'',text)\n",
    "text=re.sub(\"''/''\",'',text)\n",
    "text=re.sub(\"/\",' ',text)\n",
    "text=re.sub(\"''/''\",'',text)\n",
    "text=re.sub(\" , , \",'',text)\n",
    "text=re.sub(\" . . \",'',text)\n",
    "text=re.sub(\" -- -- \",'',text)\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'at', 'Fulton', 'np-tl', 'County', 'nn-tl', 'Grand', 'jj-tl', 'Jury', 'nn-tl', 'said', 'vbd', 'Friday', 'nr', 'an', 'at', 'investigation', 'nn', 'of', 'in', 'Atlanta', \"'s\", 'np', '$', 'recent', 'jj', 'primary', 'nn', 'election', 'nn', 'produced', 'vbd', 'no', 'at', 'evidence', 'nn', 'that', 'cs', 'any', 'dti', 'irregularities', 'nns', 'took', 'vbd', 'place', 'nnThe', 'at', 'jury', 'nn', 'further', 'rbr', 'said', 'vbd', 'in', 'in', 'term-end', 'nn', 'presentments', 'nns', 'that', 'cs', 'the', 'at', 'City', 'nn-tl', 'Executive', 'jj-tl', 'Committee', 'nn-tlwhich', 'wdt', 'had', 'hvd', 'over-all', 'jj', 'charge', 'nn', 'of', 'in', 'the', 'at', 'election', 'nn', 'deserves', 'vbz', 'the', 'at', 'praise', 'nn', 'and', 'cc', 'thanks', 'nns', 'of', 'in', 'the', 'at', 'City', 'nn-tl', 'of', 'in-tl']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text) # Tokenizing the file\n",
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('at', 'IN'),\n",
       " ('Fulton', 'NNP'),\n",
       " ('np-tl', 'JJ'),\n",
       " ('County', 'NNP'),\n",
       " ('nn-tl', 'JJ'),\n",
       " ('Grand', 'NNP'),\n",
       " ('jj-tl', 'JJ'),\n",
       " ('Jury', 'NNP'),\n",
       " ('nn-tl', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('vbd', 'JJ'),\n",
       " ('Friday', 'NNP'),\n",
       " ('nr', 'FW'),\n",
       " ('an', 'DT')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags=nltk.pos_tag(tokens) # Generating Pos Tags using nltk library\n",
    "pos_tags[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    return {\n",
    "    'word': sentence,\n",
    "    'is_first': index == 0,\n",
    "    'is_last': index == len(sentence) - 1,\n",
    "    'is_capitalized': sentence[0].upper() == sentence[0],\n",
    "    'is_all_caps': sentence.upper() == sentence,\n",
    "    'is_all_lower': sentence.lower() == sentence,\n",
    "    'prefix-1': sentence[0],\n",
    "    'prefix-2': sentence[:2],\n",
    "    'prefix-3': sentence[:3],\n",
    "    'suffix-1': sentence[-1],\n",
    "    'suffix-2': sentence[-2:],\n",
    "    'suffix-3': sentence[-3:],\n",
    "#     'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "#     'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "    'has_hyphen': '-' in sentence,\n",
    "    'is_numeric': sentence.isdigit(),\n",
    "    'capitals_inside': sentence[1:].lower() != sentence[1:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    "    for tagged in tagged_sentences:\n",
    "        X.append(features(tagged[0], range(len(tagged_sentences))))\n",
    "        y.append(tagged[1])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(.75 * len(pos_tags))\n",
    "training_sentences = pos_tags[:cutoff]\n",
    "test_sentences = pos_tags[cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting pos tags to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = transform_to_dataset(training_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intializing Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='entropy'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('classifier', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X[:20000],y[:20000]) # This can take huge time and system crash, proceed from smaller set of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:77.203%\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = transform_to_dataset(test_sentences)\n",
    "print (\"Accuracy:{:.3%}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"This is basic POS Tagging assignment.\"\n",
    "sentence_1_tokens = word_tokenize(sentence_1)\n",
    "tags = clf.predict([features(tokens, range(len(sentence_1_tokens))) for tokens in sentence_1_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens      POS Tags\n",
      "\n",
      "This              DT\n",
      "is               VBZ\n",
      "basic             JJ\n",
      "POS              NNP\n",
      "Tagging          NNP\n",
      "assignment        NN\n",
      ".                  .\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<10}{:>10}\".format(\"Tokens\",\"POS Tags\"))\n",
    "print()\n",
    "for i in range(len(sentence_1_tokens)):\n",
    "    print(\"{:<10}{:>10}\".format(sentence_1_tokens[i],tags[i]))\n",
    "#     print(tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_2 = \"For almost one-sixth of the national population discrimination in the free selection of residence casts a considerable shadow upon these values assumed as self-evident by most Americans .\"\n",
    "sentence_2_tokens = word_tokenize(sentence_2)\n",
    "tags_2 = clf.predict([features(tokens, range(len(sentence_2_tokens))) for tokens in sentence_2_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens      POS Tags\n",
      "\n",
      "For              NNP\n",
      "almost            RB\n",
      "one-sixth         RB\n",
      "of                IN\n",
      "the               DT\n",
      "national          JJ\n",
      "population        NN\n",
      "discrimination        NN\n",
      "in                IN\n",
      "the               DT\n",
      "free              JJ\n",
      "selection         NN\n",
      "of                IN\n",
      "residence         NN\n",
      "casts            NNS\n",
      "a                 DT\n",
      "considerable        NN\n",
      "shadow            VB\n",
      "upon              IN\n",
      "these             DT\n",
      "values           NNS\n",
      "assumed          VBN\n",
      "as                IN\n",
      "self-evident        NN\n",
      "by                IN\n",
      "most             JJS\n",
      "Americans       NNPS\n",
      ".                  .\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<10}{:>10}\".format(\"Tokens\",\"POS Tags\"))\n",
    "print()\n",
    "for i in range(len(sentence_2_tokens)):\n",
    "    print(\"{:<10}{:>10}\".format(sentence_2_tokens[i],tags_2[i]))\n",
    "#     print(tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
